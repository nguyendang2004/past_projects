{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group 4: Predicting Strokes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "First, we open the strokes dataset, then we rename the columns using a dictionary of names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 70692 entries\n",
      "4395 of these had strokes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diabetes</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>high_cholesterol</th>\n",
       "      <th>cholesterol_checked</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smokes</th>\n",
       "      <th>stroke</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>physical_activity</th>\n",
       "      <th>eats_fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>has_healthcare</th>\n",
       "      <th>medical_costs</th>\n",
       "      <th>general_health</th>\n",
       "      <th>mental_health</th>\n",
       "      <th>physical_health</th>\n",
       "      <th>difficulty_walking</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diabetes  high_blood_pressure  high_cholesterol  cholesterol_checked   bmi  \\\n",
       "0       0.0                  1.0               0.0                  1.0  26.0   \n",
       "1       0.0                  1.0               1.0                  1.0  26.0   \n",
       "2       0.0                  0.0               0.0                  1.0  26.0   \n",
       "3       0.0                  1.0               1.0                  1.0  28.0   \n",
       "4       0.0                  0.0               0.0                  1.0  29.0   \n",
       "\n",
       "   smokes  stroke  heart_disease  physical_activity  eats_fruits  ...  \\\n",
       "0     0.0     0.0            0.0                1.0          0.0  ...   \n",
       "1     1.0     1.0            0.0                0.0          1.0  ...   \n",
       "2     0.0     0.0            0.0                1.0          1.0  ...   \n",
       "3     1.0     0.0            0.0                1.0          1.0  ...   \n",
       "4     1.0     0.0            0.0                1.0          1.0  ...   \n",
       "\n",
       "   has_healthcare  medical_costs  general_health  mental_health  \\\n",
       "0             1.0            0.0             3.0            5.0   \n",
       "1             1.0            0.0             3.0            0.0   \n",
       "2             1.0            0.0             1.0            0.0   \n",
       "3             1.0            0.0             3.0            0.0   \n",
       "4             1.0            0.0             2.0            0.0   \n",
       "\n",
       "   physical_health  difficulty_walking  gender   age  education  income  \n",
       "0             30.0                 0.0     1.0   4.0        6.0     8.0  \n",
       "1              0.0                 0.0     1.0  12.0        6.0     8.0  \n",
       "2             10.0                 0.0     1.0  13.0        6.0     8.0  \n",
       "3              3.0                 0.0     1.0  11.0        6.0     8.0  \n",
       "4              0.0                 0.0     0.0   8.0        5.0     8.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"strokes.csv\")\n",
    "\n",
    "print(f\"Total of {df.shape[0]} entries\")\n",
    "print(f\"{len(df[df['Stroke'] == 1])} of these had strokes\")\n",
    "\n",
    "new_column_names = {\n",
    "    \"Diabetes_binary\" : \"diabetes\", \"HighBP\" : \"high_blood_pressure\", \n",
    "    \"HighChol\" : \"high_cholesterol\", \"CholCheck\" : \"cholesterol_checked\", \n",
    "    \"BMI\" : \"bmi\", \"Smoker\" : \"smokes\", \"Stroke\" : \"stroke\", \n",
    "    \"HeartDiseaseorAttack\" : \"heart_disease\", \"PhysActivity\" : \"physical_activity\", \n",
    "    \"Fruits\" : \"eats_fruits\", \"Veggies\" : \"eats_veggies\",\n",
    "    \"HvyAlcoholConsump\" : \"drinks_alcohol\", \"AnyHealthcare\" : \"has_healthcare\", \n",
    "    \"NoDocbcCost\" : \"medical_costs\", \"GenHlth\" : \"general_health\", \n",
    "    \"MentHlth\" : \"mental_health\", \"PhysHlth\" : \"physical_health\", \"DiffWalk\" : \"difficulty_walking\", \n",
    "    \"Sex\" : \"gender\", \"Age\" : \"age\", \"Education\" : \"education\", \"Income\": \"income\"}\n",
    "\n",
    "df = df.rename(mapper = lambda col: new_column_names[col], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split the data into those with a stroke and those without a stroke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "no_strokes_per_stroke = 2\n",
    "\n",
    "with_stroke = df[df[\"stroke\"] == 1]\n",
    "\n",
    "random.seed(1234)\n",
    "random_choices = random.sample(df.index[df[\"stroke\"] == 0].tolist(), no_strokes_per_stroke*len(with_stroke))\n",
    "without_stroke = df.take(random_choices)\n",
    "\n",
    "balanced_df = pd.concat([with_stroke, without_stroke], axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split the data into the general and specific datasets, and write them to their corresponding CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_columns = [\n",
    "    \"gender\", \"age\", \"income\", \"education\",\n",
    "    \"bmi\", \"smokes\", \"eats_fruits\", \"eats_veggies\", \n",
    "    \"drinks_alcohol\", \"physical_activity\"\n",
    "]\n",
    "specific_columns = general_columns + [\n",
    "    \"diabetes\", \"high_blood_pressure\", \"high_cholesterol\", \n",
    "    \"cholesterol_checked\", \"heart_disease\", \"general_health\", \n",
    "    \"mental_health\", \"physical_health\", \"difficulty_walking\", \n",
    "    \"has_healthcare\", \"medical_costs\"\n",
    "]\n",
    "\n",
    "Y = balanced_df[\"stroke\"]\n",
    "\n",
    "general_x = balanced_df[general_columns]\n",
    "specific_x = balanced_df[specific_columns]\n",
    "\n",
    "Y.to_csv(\"Y.csv\", index=False)\n",
    "general_x.to_csv(\"general_x.csv\", index=False)\n",
    "specific_x.to_csv(\"specific_x.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poly SVM of degree 3:\n",
      "General Accuracy: 65.7%\n",
      "Took 1068.3 ms to train\n",
      "Took 221.4 ms to run\n",
      "\n",
      "Specific Accuracy: 69.2%\n",
      "Took 1059.4 ms to train\n",
      "Took 274.4 ms to run\n",
      "\n",
      "\n",
      "Poly SVM of degree 4:\n",
      "General Accuracy: 65.7%\n",
      "Took 1249.5 ms to train\n",
      "Took 230.9 ms to run\n",
      "\n",
      "Specific Accuracy: 69.9%\n",
      "Took 1143.1 ms to train\n",
      "Took 281.0 ms to run\n",
      "\n",
      "\n",
      "Linear SVM:\n",
      "General Accuracy: 65.7%\n",
      "Took 855.7 ms to train\n",
      "Took 192.2 ms to run\n",
      "\n",
      "Specific Accuracy: 73.8%\n",
      "Took 912.7 ms to train\n",
      "Took 232.6 ms to run\n",
      "\n",
      "\n",
      "rbf SVM:\n",
      "General Accuracy: 65.7%\n",
      "Took 986.9 ms to train\n",
      "Took 756.9 ms to run\n",
      "\n",
      "Specific Accuracy: 69.4%\n",
      "Took 1190.8 ms to train\n",
      "Took 858.6 ms to run\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_circles, make_classification, make_moons\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "names = [\n",
    "    \"Poly SVM of degree 3\",\n",
    "    \"Poly SVM of degree 4\",\n",
    "    \"Linear SVM\",\n",
    "    \"rbf SVM\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    SVC(kernel=\"poly\", C=0.025, random_state=42),\n",
    "    SVC(kernel=\"poly\", degree =4, C=0.025, random_state=42),\n",
    "    SVC(kernel=\"linear\", C=0.025, random_state=42),\n",
    "    SVC(kernel=\"rbf\", C=0.025, random_state=42),\n",
    "]\n",
    "\n",
    "classifiers2 = [\n",
    "    SVC(kernel=\"poly\", C=0.025, random_state=42),\n",
    "    SVC(kernel=\"poly\", degree =4, C=0.025, random_state=42),\n",
    "    SVC(kernel=\"linear\", C=0.025, random_state=42),\n",
    "    SVC(kernel=\"rbf\", C=0.025, random_state=42),\n",
    "]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    general_x, Y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    specific_x, Y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "general_accuracies = []\n",
    "specific_accuracies = []\n",
    "\n",
    "general_confusion = []\n",
    "specific_confusion = []\n",
    "\n",
    "\n",
    "# iterate over classifiers\n",
    "for name, clf, clf2 in zip(names, classifiers, classifiers2):\n",
    "    print(f\"{name}:\")\n",
    "    t0 = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    t2 = time.time()\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    general_accuracies.append(accuracy)\n",
    "    general_confusion.append((y_test, y_pred))\n",
    "    print(f\"General Accuracy: {round(accuracy*100,1)}%\")\n",
    "    print(f\"Took {round((t1-t0) * 1000, 1)} ms to train\")\n",
    "    print(f\"Took {round((t2-t1) * 1000, 1)} ms to run\\n\")\n",
    "    \n",
    "    t0 = time.time()\n",
    "    clf2.fit(X_train2, y_train2)\n",
    "    t1 = time.time()\n",
    "    y_pred2 = clf2.predict(X_test2)\n",
    "    t2 = time.time()\n",
    "    accuracy = accuracy_score(y_test2, y_pred2)\n",
    "    specific_accuracies.append(accuracy)\n",
    "    specific_confusion.append((y_test2, y_pred2))\n",
    "    print(f\"Specific Accuracy: {round(accuracy*100,1)}%\")\n",
    "    print(f\"Took {round((t1-t0) * 1000, 1)} ms to train\")\n",
    "    print(f\"Took {round((t2-t1) * 1000, 1)} ms to run\\n\\n\")\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "General Accuracy: 66.2%\n",
      "Took 23.8 ms to train\n",
      "Took 4.7 ms to run\n",
      "\n",
      "Specific Accuracy: 70.8%\n",
      "Took 20.4 ms to train\n",
      "Took 2.5 ms to run\n",
      "\n",
      "\n",
      "Gaussian Process:\n",
      "General Accuracy: 66.7%\n",
      "Took 2.1 ms to train\n",
      "Took 0.7 ms to run\n",
      "\n",
      "Specific Accuracy: 72.3%\n",
      "Took 2.2 ms to train\n",
      "Took 0.7 ms to run\n",
      "\n",
      "\n",
      "AdaBoost:\n",
      "General Accuracy: 68.4%\n",
      "Took 151.8 ms to train\n",
      "Took 12.6 ms to run\n",
      "\n",
      "Specific Accuracy: 75.1%\n",
      "Took 188.8 ms to train\n",
      "Took 12.3 ms to run\n",
      "\n",
      "\n",
      "Decision Tree:\n",
      "General Accuracy: 67.4%\n",
      "Took 6.7 ms to train\n",
      "Took 0.7 ms to run\n",
      "\n",
      "Specific Accuracy: 74.3%\n",
      "Took 9.8 ms to train\n",
      "Took 0.9 ms to run\n",
      "\n",
      "\n",
      "Linear SVM:\n",
      "General Accuracy: 65.7%\n",
      "Took 898.4 ms to train\n",
      "Took 195.7 ms to run\n",
      "\n",
      "Specific Accuracy: 69.4%\n",
      "Took 1203.1 ms to train\n",
      "Took 859.5 ms to run\n",
      "\n",
      "\n",
      "Logistic Regression:\n",
      "General Accuracy: 68.3%\n",
      "Took 140.0 ms to train\n",
      "Took 7.6 ms to run\n",
      "\n",
      "Specific Accuracy: 75.1%\n",
      "Took 618.9 ms to train\n",
      "Took 3.5 ms to run\n",
      "\n",
      "\n",
      "Ensemble:\n",
      "General Accuracy: 68.4%\n",
      "Specific Accuracy: 75.1%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_circles, make_classification, make_moons\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "names = [\n",
    "    \"Random Forest\",\n",
    "    \"Gaussian Process\",\n",
    "    \"AdaBoost\",\n",
    "    \"Decision Tree\",\n",
    "    \"Linear SVM\",\n",
    "    \"Logistic Regression\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    RandomForestClassifier(\n",
    "        max_depth=5, n_estimators=10, max_features=1, random_state=42\n",
    "    ),\n",
    "    GaussianNB(),\n",
    "    AdaBoostClassifier(random_state=42),\n",
    "    DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    SVC(kernel=\"linear\", C=0.025, random_state=42),\n",
    "    LogisticRegression(max_iter=10000, random_state=42),\n",
    "]\n",
    "\n",
    "classifiers2 = [\n",
    "    RandomForestClassifier(\n",
    "        max_depth=5, n_estimators=10, max_features=1, random_state=42\n",
    "    ),\n",
    "    GaussianNB(),\n",
    "    AdaBoostClassifier(random_state=42),\n",
    "    DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    SVC(kernel=\"linear\", C=0.025, random_state=42),\n",
    "    LogisticRegression(max_iter=10000, random_state=42),\n",
    "]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    general_x, Y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(\n",
    "    specific_x, Y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "general_accuracies = []\n",
    "specific_accuracies = []\n",
    "\n",
    "general_confusion = []\n",
    "specific_confusion = []\n",
    "\n",
    "\n",
    "# iterate over classifiers\n",
    "for name, clf, clf2 in zip(names, classifiers, classifiers2):\n",
    "    print(f\"{name}:\")\n",
    "    t0 = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    t1 = time.time()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    t2 = time.time()\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    general_accuracies.append(accuracy)\n",
    "    general_confusion.append((y_test, y_pred))\n",
    "    print(f\"General Accuracy: {round(accuracy*100,1)}%\")\n",
    "    print(f\"Took {round((t1-t0) * 1000, 1)} ms to train\")\n",
    "    print(f\"Took {round((t2-t1) * 1000, 1)} ms to run\\n\")\n",
    "    \n",
    "    t0 = time.time()\n",
    "    clf2.fit(X_train2, y_train2)\n",
    "    t1 = time.time()\n",
    "    y_pred2 = clf2.predict(X_test2)\n",
    "    t2 = time.time()\n",
    "    accuracy = accuracy_score(y_test2, y_pred2)\n",
    "    specific_accuracies.append(accuracy)\n",
    "    specific_confusion.append((y_test2, y_pred2))\n",
    "    print(f\"Specific Accuracy: {round(accuracy*100,1)}%\")\n",
    "    print(f\"Took {round((t1-t0) * 1000, 1)} ms to train\")\n",
    "    print(f\"Took {round((t2-t1) * 1000, 1)} ms to run\\n\\n\")\n",
    "    \n",
    "def ensemble(classifiers, classifiers2, X_test, X_test2, y_test, y_test2, general_accuracies, specific_accuracies):\n",
    "    y_pred = np.zeros(y_test.shape)\n",
    "    y_pred2 = np.zeros(y_test2.shape)\n",
    "    for i, (clf, clf2) in enumerate(zip(classifiers, classifiers2)):   \n",
    "        y_pred += general_accuracies[i] * clf.predict(X_test)\n",
    "        y_pred2 += specific_accuracies[i] * clf2.predict(X_test2)\n",
    "    y_pred /= sum(general_accuracies)\n",
    "    y_pred2 /= sum(specific_accuracies)\n",
    "    \n",
    "    y_pred = y_pred.round(0)\n",
    "    y_pred2 = y_pred2.round(0)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy2 = accuracy_score(y_test2, y_pred2)\n",
    "    general_confusion.append((y_test, y_pred))\n",
    "    specific_confusion.append((y_test2, y_pred2))\n",
    "    \n",
    "    print(f\"Ensemble:\")\n",
    "    print(f\"General Accuracy: {round(accuracy*100,1)}%\")\n",
    "    print(f\"Specific Accuracy: {round(accuracy2*100,1)}%\")\n",
    "    \n",
    "\n",
    "ensemble(classifiers, classifiers2, X_test, X_test2, y_test, y_test2, general_accuracies, specific_accuracies)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
